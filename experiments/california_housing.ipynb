{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and code to load in the data and model is used by both conditions and included in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import lightgbm\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "\n",
    "AWS_BASE_URL = 'https://pyreal-data.s3.amazonaws.com/'\n",
    "data_url = urljoin(AWS_BASE_URL, \"usability_study/california.csv\")\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "data = data[data[\"median_house_value\"] < 500000]\n",
    "\n",
    "X_orig = data.drop(\"median_house_value\", axis=1)\n",
    "y = data[\"median_house_value\"]\n",
    "\n",
    "x_to_encode = X_orig[[\"ocean_proximity\"]]\n",
    "ohe = SklearnOneHotEncoder(sparse=False).fit(x_to_encode)\n",
    "encoded_columns = ohe.get_feature_names(x_to_encode.columns)\n",
    "index = x_to_encode.index\n",
    "ocean_encoded = ohe.transform(x_to_encode)\n",
    "ocean_encoded = pd.DataFrame(ocean_encoded, columns=encoded_columns, index=index)\n",
    "X_explain = pd.concat([X_orig.drop(\"ocean_proximity\", axis=\"columns\"), ocean_encoded], axis=1)\n",
    "\n",
    "model = lightgbm.LGBMRegressor().fit(X_explain, y)\n",
    "\n",
    "cities_url = urljoin(AWS_BASE_URL, \"usability_study/cal_cities_lat_long.csv\")\n",
    "cities = pd.read_csv(cities_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Condition: No use of Pyreal, local feature contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     housing_median_age   total_rooms  total_bedrooms    population  \\\n",
      "0           6893.014235 -16313.670432    -5190.310484  33760.753826   \n",
      "1          -2298.934857  27908.491126     8476.079304 -11447.901431   \n",
      "2          14970.760960  -3487.840827    -8985.475965  29686.294120   \n",
      "3          24124.189212  -8151.549179   -10196.789004  29334.750209   \n",
      "4          14963.790748  -1584.453407    -5965.421183  38996.119118   \n",
      "..                  ...           ...             ...           ...   \n",
      "495         1671.992464  -3761.594139    -6998.997871  15941.879614   \n",
      "496         8375.826925  -2586.061748      770.787216   8517.544665   \n",
      "497         2775.590667 -11377.285389    -8782.096901  29569.383881   \n",
      "498         -338.094075  -3205.528880    -6418.619379   7110.906943   \n",
      "499         4708.765326 -18940.546231    -9786.793549  29577.470073   \n",
      "\n",
      "      households  median_income  ocean_proximity          city  \n",
      "0   -5475.789824  151472.623759     21198.829465  36963.710606  \n",
      "1    5344.552388  157792.628613     20067.914812  27381.548822  \n",
      "2   -3289.218406  127204.446845     19639.868088  18249.016314  \n",
      "3    -214.625759   71920.886859     19961.445010  20094.671306  \n",
      "4   -1173.227777    2858.634469     25568.854449   6714.033880  \n",
      "..           ...            ...              ...           ...  \n",
      "495 -3478.391198  -62193.668112     19681.197005 -22541.276463  \n",
      "496 -2434.602276  -66735.583779     20034.975549 -19391.165641  \n",
      "497 -7316.214002  -44432.914895     20398.193625 -21730.554897  \n",
      "498 -3322.298435  -61942.757080     18818.869763 -17930.572027  \n",
      "499 -9082.904403  -26429.674655     21897.290691 -20531.319571  \n",
      "\n",
      "[500 rows x 8 columns]\n",
      "Runtime:  1.70192551612854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "import shap\n",
    "\n",
    "start = time.time()\n",
    "x_to_encode = X_orig[[\"ocean_proximity\"]]\n",
    "ohe = SklearnOneHotEncoder(sparse=False).fit(x_to_encode)\n",
    "encoded_columns = ohe.get_feature_names(x_to_encode.columns)\n",
    "index = x_to_encode.index\n",
    "ocean_encoded = ohe.transform(x_to_encode)\n",
    "ocean_encoded = pd.DataFrame(ocean_encoded, columns=encoded_columns, index=index)\n",
    "X_explain = pd.concat([X_orig.drop(\"ocean_proximity\", axis=\"columns\"), ocean_encoded], axis=1)\n",
    "X_interpret = X_orig.copy()\n",
    "for index, row in cities.iterrows():\n",
    "    lat = row[\"Latitude\"]\n",
    "    lon = row[\"Longitude\"]\n",
    "    X_interpret.loc[(X_interpret[\"latitude\"] > lat-0.1) & (X_interpret[\"latitude\"] < lat+0.1) & (X_interpret[\"longitude\"] > lon-0.1) & (X_interpret[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "X_interpret = X_interpret.drop(\"latitude\", axis=1)\n",
    "X_interpret = X_interpret.drop(\"longitude\", axis=1)\n",
    "columns = X_explain.columns\n",
    "explainer = shap.Explainer(model, X_explain)\n",
    "explanation = explainer(X_explain.iloc[0:500])\n",
    "explanation_df = pd.DataFrame(explanation.values, columns=columns)\n",
    "encoded_features = [item for item in encoded_columns if item.startswith(\"ocean_proximity_\")]\n",
    "summed_contribution = explanation_df[encoded_features].sum(axis=1)\n",
    "explanation_df = explanation_df.drop(encoded_features, axis=\"columns\")\n",
    "explanation_df[\"ocean_proximity\"] = summed_contribution\n",
    "explanation_df[\"city\"] = explanation_df[\"longitude\"] + explanation_df[\"latitude\"]\n",
    "explanation_df = explanation_df.drop(\"longitude\", axis=1)\n",
    "explanation_df = explanation_df.drop(\"latitude\", axis=1)\n",
    "shap_explanation = explanation_df #***\n",
    "print(shap_explanation)\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Experimental Condition: Using Pyreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     housing_median_age   total_rooms  total_bedrooms    population  \\\n",
      "0           6893.014235 -16313.670432    -5190.310484  33760.753826   \n",
      "1          -2298.934857  27908.491126     8476.079304 -11447.901431   \n",
      "2          14970.760960  -3487.840827    -8985.475965  29686.294120   \n",
      "3          24124.189212  -8151.549179   -10196.789004  29334.750209   \n",
      "4          14963.790748  -1584.453407    -5965.421183  38996.119118   \n",
      "..                  ...           ...             ...           ...   \n",
      "495         1671.992464  -3761.594139    -6998.997871  15941.879614   \n",
      "496         8375.826925  -2586.061748      770.787216   8517.544665   \n",
      "497         2775.590667 -11377.285389    -8782.096901  29569.383881   \n",
      "498         -338.094075  -3205.528880    -6418.619379   7110.906943   \n",
      "499         4708.765326 -18940.546231    -9786.793549  29577.470073   \n",
      "\n",
      "      households  median_income  ocean_proximity          city  \n",
      "0   -5475.789824  151472.623759     21198.829465  36963.710606  \n",
      "1    5344.552388  157792.628613     20067.914812  27381.548822  \n",
      "2   -3289.218406  127204.446845     19639.868088  18249.016314  \n",
      "3    -214.625759   71920.886859     19961.445010  20094.671306  \n",
      "4   -1173.227777    2858.634469     25568.854449   6714.033880  \n",
      "..           ...            ...              ...           ...  \n",
      "495 -3478.391198  -62193.668112     19681.197005 -22541.276463  \n",
      "496 -2434.602276  -66735.583779     20034.975549 -19391.165641  \n",
      "497 -7316.214002  -44432.914895     20398.193625 -21730.554897  \n",
      "498 -3322.298435  -61942.757080     18818.869763 -17930.572027  \n",
      "499 -9082.904403  -26429.674655     21897.290691 -20531.319571  \n",
      "\n",
      "[500 rows x 8 columns]\n",
      "Runtime:  1.9233043193817139\n"
     ]
    }
   ],
   "source": [
    "from pyreal.transformers import Transformer, fit_transformers, OneHotEncoder\n",
    "from pyreal.explainers import LocalFeatureContribution\n",
    "from pyreal.types.explanations.dataframe import AdditiveFeatureContributionExplanation\n",
    "\n",
    "start = time.time()\n",
    "class CityConverter(Transformer): #****\n",
    "  def __init__(self): #****\n",
    "    self.cities = cities #****\n",
    "  def data_transform(self, x): #****\n",
    "    for index, row in self.cities.iterrows():\n",
    "      lat = row[\"Latitude\"]\n",
    "      lon = row[\"Longitude\"]\n",
    "      x.loc[(x[\"latitude\"] > lat-0.1) & (x[\"latitude\"] < lat+0.1) & (x[\"longitude\"] > lon-0.1) & (x[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "    x = x.drop(\"latitude\", axis=1)\n",
    "    x = x.drop(\"longitude\", axis=1)\n",
    "    return x #****\n",
    "  def transform_explanation_additive_contributions(self, explanation): #****\n",
    "    explanation = explanation.get()\n",
    "    explanation[\"city\"] = explanation[\"longitude\"] + explanation[\"latitude\"]\n",
    "    explanation = explanation.drop(\"longitude\", axis=1)\n",
    "    explanation = explanation.drop(\"latitude\", axis=1)\n",
    "    return AdditiveFeatureContributionExplanation(explanation)\n",
    "one_hot_encoder = OneHotEncoder(columns=[\"ocean_proximity\"])\n",
    "city_converter = CityConverter()\n",
    "e_transformers = [one_hot_encoder]\n",
    "i_transformers = [city_converter]\n",
    "fit_transformers(e_transformers, X_orig)\n",
    "fit_transformers(i_transformers, X_orig)\n",
    "local_explainer = LocalFeatureContribution(model, x_train_orig=X_orig, y_orig=y, e_algorithm=\"shap\", e_transformers=e_transformers, i_transformers=i_transformers, fit_on_init=True)\n",
    "pyreal_explanation = local_explainer.produce(X_orig.iloc[0:500])\n",
    "print(pyreal_explanation)\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in explanations:  \n"
     ]
    },
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: []\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Difference in explanations:  \")\n",
    "pyreal_explanation.compare(shap_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 19386/19648 [00:47<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   housing_median_age  total_rooms  total_bedrooms    population   households  \\\n",
      "0         5703.277746  8538.330061     7876.322111  14273.961072  2172.921944   \n",
      "\n",
      "   median_income  ocean_proximity          city  \n",
      "0   34165.340693     28072.309062  75501.488753  \n",
      "Runtime:  48.118314266204834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "x_to_encode = X_orig[[\"ocean_proximity\"]]\n",
    "ohe = SklearnOneHotEncoder(sparse=False).fit(x_to_encode)\n",
    "encoded_columns = ohe.get_feature_names(x_to_encode.columns)\n",
    "index = x_to_encode.index\n",
    "ocean_encoded = ohe.transform(x_to_encode)\n",
    "ocean_encoded = pd.DataFrame(ocean_encoded, columns=encoded_columns, index=index)\n",
    "X_explain = pd.concat([X_orig.drop(\"ocean_proximity\", axis=\"columns\"), ocean_encoded], axis=1)\n",
    "X_interpret = X_orig.copy()\n",
    "for index, row in cities.iterrows():\n",
    "    lat = row[\"Latitude\"]\n",
    "    lon = row[\"Longitude\"]\n",
    "    X_interpret.loc[(X_interpret[\"latitude\"] > lat-0.1) & (X_interpret[\"latitude\"] < lat+0.1) & (X_interpret[\"longitude\"] > lon-0.1) & (X_interpret[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "X_interpret = X_interpret.drop(\"latitude\", axis=1)\n",
    "X_interpret = X_interpret.drop(\"longitude\", axis=1)\n",
    "columns = X_explain.columns\n",
    "explainer = shap.Explainer(model, X_explain)\n",
    "explanation = explainer(X_explain)\n",
    "explanation = np.mean(np.absolute(explanation.values), axis=0).reshape(1, -1)\n",
    "explanation_df = pd.DataFrame(explanation, columns=columns)\n",
    "encoded_features = [item for item in encoded_columns if item.startswith(\"ocean_proximity_\")]\n",
    "summed_contribution = explanation_df[encoded_features].sum(axis=1)\n",
    "explanation_df = explanation_df.drop(encoded_features, axis=\"columns\")\n",
    "explanation_df[\"ocean_proximity\"] = summed_contribution\n",
    "explanation_df[\"city\"] = explanation_df[\"longitude\"] + explanation_df[\"latitude\"]\n",
    "explanation_df = explanation_df.drop(\"longitude\", axis=1)\n",
    "explanation_df = explanation_df.drop(\"latitude\", axis=1)\n",
    "shap_explanation = explanation_df #***\n",
    "print(shap_explanation)\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Condition: Using Pyreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 19378/19648 [00:47<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   housing_median_age  total_rooms  total_bedrooms    population   households  \\\n",
      "0         5703.277746  8538.330061     7876.322111  14273.961072  2172.921944   \n",
      "\n",
      "   median_income  ocean_proximity          city  \n",
      "0   34165.340693     28072.309062  75501.488753  \n",
      "Runtime:  47.99860215187073\n"
     ]
    }
   ],
   "source": [
    "from pyreal.transformers import Transformer, fit_transformers, OneHotEncoder\n",
    "from pyreal.explainers import LocalFeatureContribution, GlobalFeatureImportance\n",
    "from pyreal.types.explanations.dataframe import AdditiveFeatureContributionExplanation\n",
    "\n",
    "start = time.time()\n",
    "class CityConverter(Transformer): #****\n",
    "  def __init__(self): #****\n",
    "    self.cities = cities #****\n",
    "  def data_transform(self, x): #****\n",
    "    for index, row in self.cities.iterrows():\n",
    "      lat = row[\"Latitude\"]\n",
    "      lon = row[\"Longitude\"]\n",
    "      x.loc[(x[\"latitude\"] > lat-0.1) & (x[\"latitude\"] < lat+0.1) & (x[\"longitude\"] > lon-0.1) & (x[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "    x = x.drop(\"latitude\", axis=1)\n",
    "    x = x.drop(\"longitude\", axis=1)\n",
    "    return x #****\n",
    "  def transform_explanation_additive_contributions(self, explanation): #****\n",
    "    explanation = explanation.get()\n",
    "    explanation[\"city\"] = explanation[\"longitude\"] + explanation[\"latitude\"]\n",
    "    explanation = explanation.drop(\"longitude\", axis=1)\n",
    "    explanation = explanation.drop(\"latitude\", axis=1)\n",
    "    return AdditiveFeatureContributionExplanation(explanation)\n",
    "one_hot_encoder = OneHotEncoder(columns=[\"ocean_proximity\"])\n",
    "city_converter = CityConverter()\n",
    "e_transformers = [one_hot_encoder]\n",
    "i_transformers = [city_converter]\n",
    "fit_transformers(e_transformers, X_orig)\n",
    "fit_transformers(i_transformers, X_orig)\n",
    "global_explainer = GlobalFeatureImportance(model, x_train_orig=X_orig, y_orig=y, e_algorithm=\"shap\", e_transformers=e_transformers, i_transformers=i_transformers, fit_on_init=True)\n",
    "pyreal_explanation = global_explainer.produce()\n",
    "print(pyreal_explanation)\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  0.17199969291687012\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "\n",
    "start = time.time()\n",
    "numeric_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "categorical_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "numeric_cols = X_orig.dropna(axis=\"columns\", how=\"all\") \\\n",
    "            .select_dtypes(include=\"number\").columns\n",
    "categorical_cols = X_orig.dropna(axis=\"columns\", how=\"all\") \\\n",
    "    .select_dtypes(exclude=\"number\").columns\n",
    "numeric_imputer.fit(X_orig[numeric_cols])\n",
    "categorical_imputer.fit(X_orig[categorical_cols])\n",
    "new_numeric_cols = numeric_imputer.transform(X_orig[numeric_cols])\n",
    "new_categorical_cols = categorical_imputer.transform(X_orig[categorical_cols])\n",
    "X_explain = pd.concat([pd.DataFrame(new_numeric_cols, columns=numeric_cols, index=X_orig.index),\n",
    "                          pd.DataFrame(new_categorical_cols, columns=categorical_cols,\n",
    "                                       index=X_orig.index)], axis=1)\n",
    "x_to_encode = X_explain[[\"ocean_proximity\"]]\n",
    "ohe = SklearnOneHotEncoder(sparse=False).fit(x_to_encode)\n",
    "encoded_columns = ohe.get_feature_names(x_to_encode.columns)\n",
    "index = x_to_encode.index\n",
    "ocean_encoded = ohe.transform(x_to_encode)\n",
    "ocean_encoded = pd.DataFrame(ocean_encoded, columns=encoded_columns, index=index)\n",
    "X_explain = pd.concat([X_explain.drop(\"ocean_proximity\", axis=\"columns\"), ocean_encoded], axis=1)\n",
    "sklearn_explanation = tree.DecisionTreeRegressor()\n",
    "results = model.predict(X_explain)\n",
    "sklearn_explanation.fit(X_explain, model.predict(X_explain))\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime:  0.34201598167419434\n"
     ]
    }
   ],
   "source": [
    "from pyreal.explainers import DecisionTreeExplainer\n",
    "from pyreal.transformers import MultiTypeImputer\n",
    "\n",
    "start = time.time()\n",
    "one_hot_encoder = OneHotEncoder(columns=[\"ocean_proximity\"])\n",
    "imputer = MultiTypeImputer()\n",
    "e_transformers = [imputer, one_hot_encoder]\n",
    "fit_transformers(e_transformers, X_orig)\n",
    "local_explainer = DecisionTreeExplainer(model, x_train_orig=X_orig, y_orig=y, e_transformers=e_transformers, fit_on_init=True, is_classifier=False)\n",
    "pyreal_explanation = local_explainer.produce()\n",
    "print(\"Runtime: \", time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}