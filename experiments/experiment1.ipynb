{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and code to load in the data and model is used by both conditions and included in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "import lightgbm\n",
    "\n",
    "AWS_BASE_URL = 'https://pyreal-data.s3.amazonaws.com/'\n",
    "data_url = urljoin(AWS_BASE_URL, \"usability_study/california.csv\")\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "data = data[data[\"median_house_value\"] < 500000]\n",
    "\n",
    "X_orig = data.drop(\"median_house_value\", axis=1)\n",
    "y = data[\"median_house_value\"]\n",
    "\n",
    "model_url = urljoin(AWS_BASE_URL, \"usability_study/model.model\")\n",
    "r = requests.get(model_url, allow_redirects=True)\n",
    "open('model.model', 'wb').write(r.content)\n",
    "\n",
    "model = lightgbm.Booster(model_file='model.model')\n",
    "\n",
    "cities_url = urljoin(AWS_BASE_URL, \"usability_study/cal_cities_lat_long.csv\")\n",
    "cities = pd.read_csv(cities_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control Condition: No use of Pyreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   housing_median_age  total_rooms  total_bedrooms    population   households  \\\n",
      "0         6240.231167 -6519.575265    -5066.954466  20706.379627 -9398.551951   \n",
      "\n",
      "   median_income  average_rooms  average_bedrooms  ocean_proximity  \\\n",
      "0   147004.07603   19999.074403       -650.607882     21483.632595   \n",
      "\n",
      "           city  \n",
      "0  28633.157172  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "import shap\n",
    "\n",
    "x_to_encode = X_orig[[\"ocean_proximity\"]]\n",
    "ohe = SklearnOneHotEncoder(sparse=False).fit(x_to_encode)\n",
    "encoded_columns = ohe.get_feature_names(x_to_encode.columns)\n",
    "index = x_to_encode.index\n",
    "ocean_encoded = ohe.transform(x_to_encode)\n",
    "ocean_encoded = pd.DataFrame(ocean_encoded, columns=encoded_columns, index=index)\n",
    "X_explain = pd.concat([X_orig.drop(\"ocean_proximity\", axis=\"columns\"), ocean_encoded], axis=1)\n",
    "X_explain[\"average_rooms\"] = X_explain[\"total_rooms\"] / X_explain[\"households\"]\n",
    "X_explain[\"average_bedrooms\"] = X_explain[\"total_bedrooms\"] / X_explain[\"households\"]\n",
    "\n",
    "X_interpret = X_orig.copy()\n",
    "X_interpret[\"average_rooms\"] = X_interpret[\"total_rooms\"] / X_interpret[\"households\"]\n",
    "X_interpret[\"average_bedrooms\"] = X_interpret[\"total_bedrooms\"] / X_interpret[\"households\"]\n",
    "for index, row in cities.iterrows():\n",
    "    lat = row[\"Latitude\"]\n",
    "    lon = row[\"Longitude\"]\n",
    "    X_interpret.loc[(X_interpret[\"latitude\"] > lat-0.1) & (X_interpret[\"latitude\"] < lat+0.1) & (X_interpret[\"longitude\"] > lon-0.1) & (X_interpret[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "X_interpret = X_interpret.drop(\"latitude\", axis=1)\n",
    "X_interpret = X_interpret.drop(\"longitude\", axis=1)\n",
    "\n",
    "columns = X_explain.columns\n",
    "\n",
    "explainer = shap.Explainer(model, X_explain)\n",
    "explanation = explainer(X_explain.iloc[0:1])\n",
    "explanation_df = pd.DataFrame(explanation.values, columns=columns)\n",
    "\n",
    "encoded_features = [item for item in encoded_columns if item.startswith(\"ocean_proximity_\")]\n",
    "summed_contribution = explanation_df[encoded_features].sum(axis=1)\n",
    "explanation_df = explanation_df.drop(encoded_features, axis=\"columns\")\n",
    "explanation_df[\"ocean_proximity\"] = summed_contribution\n",
    "\n",
    "explanation_df[\"city\"] = explanation_df[\"longitude\"] + explanation_df[\"latitude\"]\n",
    "explanation_df = explanation_df.drop(\"longitude\", axis=1)\n",
    "explanation_df = explanation_df.drop(\"latitude\", axis=1)\n",
    "\n",
    "shap_explanation = explanation_df\n",
    "print(shap_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experimental Condition: Using Pyreal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer class CityConverter does not have the required inverse explanation transform\n",
      "Stopping explanation transform process\n",
      "     longitude      latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0  46879.62999 -18246.472817         6240.231167 -6519.575265    -5066.954466   \n",
      "\n",
      "     population   households  median_income  average_rooms  average_bedrooms  \\\n",
      "0  20706.379627 -9398.551951   147004.07603   19999.074403       -650.607882   \n",
      "\n",
      "   ocean_proximity  \n",
      "0     21483.632595  \n"
     ]
    }
   ],
   "source": [
    "from pyreal.transformers import Transformer, fit_transformers, OneHotEncoder\n",
    "from pyreal.explainers import LocalFeatureContribution\n",
    "from pyreal.types.explanations.dataframe import AdditiveFeatureContributionExplanation\n",
    "\n",
    "class CityConverter(Transformer):\n",
    "  def __init__(self):\n",
    "    self.cities = cities\n",
    "\n",
    "  def data_transform(self, x):\n",
    "    for index, row in self.cities.iterrows():\n",
    "      lat = row[\"Latitude\"]\n",
    "      lon = row[\"Longitude\"]\n",
    "      x.loc[(x[\"latitude\"] > lat-0.1) & (x[\"latitude\"] < lat+0.1) & (x[\"longitude\"] > lon-0.1) & (x[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "    x = x.drop(\"latitude\", axis=1)\n",
    "    x = x.drop(\"longitude\", axis=1)\n",
    "    return x\n",
    "\n",
    "  def transform_explanation_additive_contributions(self, explanation):\n",
    "    explanation = explanation.get()\n",
    "    explanation[\"city\"] = explanation[\"longitude\"] + explanation[\"latitude\"]\n",
    "    explanation = explanation.drop(\"longitude\", axis=1)\n",
    "    explanation = explanation.drop(\"latitude\", axis=1)\n",
    "    return AdditiveFeatureContributionExplanation(explanation)\n",
    "\n",
    "class PerHouseholdAverager(Transformer):\n",
    "  def __init__(self, column):\n",
    "    self.column = column\n",
    "\n",
    "  def data_transform(self, x):\n",
    "    name = self.column.replace(\"total\", \"average\")\n",
    "    x[name] = x[self.column] / x[\"households\"]\n",
    "    return x\n",
    "\n",
    "  def inverse_transform_explanation(self, explanation):\n",
    "    return explanation\n",
    "\n",
    "  def transform_explanation(self, explanation):\n",
    "    return explanation\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(columns=[\"ocean_proximity\"])\n",
    "room_averager = PerHouseholdAverager(\"total_rooms\")\n",
    "bedroom_averager = PerHouseholdAverager(\"total_bedrooms\")\n",
    "city_converter = CityConverter()\n",
    "e_transformers = [one_hot_encoder, room_averager, bedroom_averager]\n",
    "i_transformers = [room_averager, bedroom_averager, city_converter]\n",
    "fit_transformers(e_transformers, X_orig)\n",
    "fit_transformers(i_transformers, X_orig)\n",
    "local_explainer = LocalFeatureContribution(model, x_train_orig=X_orig, y_orig=y, e_algorithm=\"shap\", e_transformers=e_transformers, i_transformers=i_transformers, fit_on_init=True)\n",
    "\n",
    "pyreal_explanation = local_explainer.produce(X_orig.iloc[0:1])\n",
    "print(pyreal_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     longitude      latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0  46879.62999 -18246.472817         6240.231167 -6519.575265    -5066.954466   \n",
      "\n",
      "     population   households  median_income  average_rooms  average_bedrooms  \\\n",
      "0  20706.379627 -9398.551951   147004.07603   19999.074403       -650.607882   \n",
      "\n",
      "   ocean_proximity  \n",
      "0     21483.632595  \n",
      "   housing_median_age  total_rooms  total_bedrooms    population   households  \\\n",
      "0         6240.231167 -6519.575265    -5066.954466  20706.379627 -9398.551951   \n",
      "\n",
      "   median_income  average_rooms  average_bedrooms  ocean_proximity  \\\n",
      "0   147004.07603   19999.074403       -650.607882     21483.632595   \n",
      "\n",
      "           city  \n",
      "0  28633.157172  \n"
     ]
    }
   ],
   "source": [
    "print(pyreal_explanation)\n",
    "print(shap_explanation)\n",
    "#pyreal_explanation.compare(shap_explanation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}