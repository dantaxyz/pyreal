{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d578d4",
   "metadata": {},
   "source": [
    "## Simple Four-Feature-Spaces Tutorial\n",
    "\n",
    "In this tutorial, we will work through an simple, artificial ML problem to illustrate the full `Pyreal` workflow, including four unique feature spaces and multiple explanation types.\n",
    "\n",
    "Throughout this tutorial, imagine that we are Trinket Sellers looking to price new Trinkets based on five peices of information, as described below. We are working with ML model developers who will help us train a simple model to predict prices, but we would also like some explanations to help us understand how these predictions come from the five peices of information. As you will see, Pyreal can help!\n",
    "\n",
    "\n",
    "### Problem Setup\n",
    "\n",
    "We will be predicting Trinket prices based on five peices of information:\n",
    "1. Trinket Type `type` (categorical)\n",
    "2. Trinket Color `color` (categorical)\n",
    "3. Trinket Age `age` (integer)\n",
    "4. Trinket Weight `width` (float)\n",
    "4. Trinket Height `height` (float)\n",
    "\n",
    "This information can be formatted in multiple ways - each of these introduces a new *feature space*. In this tutorial, we will go over how you can use Pyreal Explainers and Transformers to play with these four feature spaces.\n",
    "\n",
    "### Original Feature Space\n",
    "\n",
    "In this example, we have been given the data in what we will refer to as the **original** feature space, or `X_orig`. This is an arbitrary feature space, that includes the information in whatever form our data-collection team happened to use. Let's load in and take a look at this space now.\n",
    "\n",
    "We see that we have seven columns, one each for items 1 through 4 above, plus three one-hot encoded columns for the `type` feature, which encodes three possible categories - `foo`, `bar`, and `foobar`. The color feature is listed using HTML color codes, which are not very understandable. The other three features are numeric, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5988b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature space:\n"
     ]
    },
    {
     "data": {
      "text/plain": "     color  age      width     height  type_bar  type_foo  type_foobar\n0  #e51e32   41  43.569090  68.784567       1.0       0.0          0.0\n1  #f51a2f   71  84.261218  60.542412       0.0       0.0          1.0\n2  #21e308   90  71.574072  45.595469       1.0       0.0          0.0\n3  #0630cf   32  23.125698  83.431874       0.0       1.0          0.0\n4  #04d82b   44  54.253466  20.646017       0.0       0.0          1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>age</th>\n      <th>width</th>\n      <th>height</th>\n      <th>type_bar</th>\n      <th>type_foo</th>\n      <th>type_foobar</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>#e51e32</td>\n      <td>41</td>\n      <td>43.569090</td>\n      <td>68.784567</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#f51a2f</td>\n      <td>71</td>\n      <td>84.261218</td>\n      <td>60.542412</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>#21e308</td>\n      <td>90</td>\n      <td>71.574072</td>\n      <td>45.595469</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#0630cf</td>\n      <td>32</td>\n      <td>23.125698</td>\n      <td>83.431874</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#04d82b</td>\n      <td>44</td>\n      <td>54.253466</td>\n      <td>20.646017</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_orig =  pd.read_csv(\"trinket_data.csv\", index_col=0)\n",
    "y_orig = data_orig[\"price\"]\n",
    "X_orig = data_orig.drop(\"price\", axis=1)\n",
    "\n",
    "print(\"Original feature space:\")\n",
    "X_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442096c",
   "metadata": {},
   "source": [
    "### Model-Ready Feature Space\n",
    "\n",
    "Let's go ahead and train a model to predict the price variable from the features. To do so, we will first need to transform the data to a model-ready standpoint. Our ML development team has done their research and feature engineering, and suggested that a simple linear regression model may work well. They have also collected the following domain knowledge that may be useful for feature engineering:\n",
    "1. All trinkets are generally \"reddish\" or \"blueish\" - this is much more important to their price than the exact HTML color value.\n",
    "2. Bigger trinkets sell for more - but the difference between width and height is arbitrary. In fact, only the larger of these axis matter\n",
    "\n",
    "Based on this information, combined with the requirements of a linear regression model, let's put together some transformers using Pyreal's `transformer` package, and take a look at what the model-ready feature space looks like. As you can see, this feature space includes one-hot encoded and aggregated features.\n",
    "\n",
    "We will use some pre-defined Pyreal transformers, that cover common transformation types, and also define some of our own using the Transformer base class, such as converting HTML colors codes to `red` and `blue`.\n",
    "\n",
    "Note that Pyreal transformers take three flags: `model`, `interpret`, and `algorithm`. For now, we are just using the former. By setting `model` to `True`, we are telling Pyreal Explainers that these transformers are required to get the data to the feature space expected by the model. Note that `model==True` is the default flag; for the purposes of being clear in this tutorial, we are setting it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2a5fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready feature space:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age  type_bar  type_foo  type_foobar  color_blue  color_green  color_red  \\\n0   41       1.0       0.0          0.0         0.0          0.0        1.0   \n1   71       0.0       0.0          1.0         0.0          0.0        1.0   \n2   90       1.0       0.0          0.0         0.0          1.0        0.0   \n3   32       0.0       1.0          0.0         1.0          0.0        0.0   \n4   44       0.0       0.0          1.0         0.0          1.0        0.0   \n\n   MAX(width,height)  \n0          68.784567  \n1          84.261218  \n2          71.574072  \n3          83.431874  \n4          54.253466  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>type_bar</th>\n      <th>type_foo</th>\n      <th>type_foobar</th>\n      <th>color_blue</th>\n      <th>color_green</th>\n      <th>color_red</th>\n      <th>MAX(width,height)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>68.784567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>71</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>84.261218</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>90</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>71.574072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>83.431874</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>54.253466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyreal.transformers import Transformer, OneHotEncoder, Mappings, MappingsOneHotDecoder, FeatureSelectTransformer\n",
    "from pyreal.transformers import fit_transformers, run_transformers\n",
    "\n",
    "\n",
    "def hex_to_color_name(h):\n",
    "    h = h.lstrip('#')\n",
    "    rgb = tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return [\"red\", \"green\", \"blue\"][rgb.index(max(rgb))]\n",
    "\n",
    "class ColorTransformer(Transformer):\n",
    "    \"\"\"\n",
    "    Transforms a hex color to `red` or `blue`\n",
    "    \"\"\"\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        self.columns = columns\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def fit(self, x):\n",
    "        return self\n",
    "\n",
    "    def data_transform(self, x):\n",
    "        for col in self.columns:\n",
    "            x[col] = x[col].apply(hex_to_color_name)\n",
    "        return x\n",
    "\n",
    "class MaxAggregator(Transformer):\n",
    "    \"\"\"\n",
    "    Converts a set of numeric features to a single feature of the max value\n",
    "    \"\"\"\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        self.columns = columns\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def data_transform(self, x):\n",
    "        column_name = \"MAX(\"\n",
    "        column_name += \",\".join(self.columns)\n",
    "        column_name += \")\"\n",
    "        x[column_name] = x[self.columns].max(axis=1)\n",
    "        x = x.drop(self.columns, axis=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "colorTransformer = ColorTransformer(columns = [\"color\"], model=True)\n",
    "colorEncoder = OneHotEncoder(columns = [\"color\"], model=True)\n",
    "maxAggregator = MaxAggregator(columns=[\"width\", \"height\"], model=True)\n",
    "# The featureSelect transformer keeps the order of columns consistent,\n",
    "#   which can be helpful with complex transformations\n",
    "featureSelect = FeatureSelectTransformer(['age', 'type_bar', 'type_foo', 'type_foobar',\n",
    "                                          'color_blue', 'color_green', 'color_red',\n",
    "                                          'MAX(width,height)'], model=True)\n",
    "\n",
    "model_transformers = [maxAggregator, colorTransformer, colorEncoder, featureSelect]\n",
    "X_model = fit_transformers(model_transformers, X_orig)\n",
    "print(\"Model ready feature space:\")\n",
    "X_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d39c1c",
   "metadata": {},
   "source": [
    "And now let's train a model and check the score..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144f4bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model r-squared: 0.9998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_model[0:400], y_orig[0:400])\n",
    "print(\"Model r-squared: %.4f\" % model.score(X_model[401:], y_orig[401:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419468e",
   "metadata": {},
   "source": [
    "Our model development team has confirmed that this model performs well - but we would like to know how its making its predictions. How are our features interacting to give a price? Let's address this question by generating a local explanation for the first item in our dataset, using the popular explanation algorithm SHAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f29df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "from pyreal.utils import visualize\n",
    "\n",
    "explainer = shap.LinearExplainer(model, shap.maskers.Independent(data = X_model))\n",
    "shap_values = explainer.shap_values(X_model[0:1])[0]\n",
    "explanation = pd.DataFrame([shap_values], columns=X_model.columns)\n",
    "\n",
    "visualize.plot_top_contributors(explanation, select_by=\"absolute\",\n",
    "                                values=X_model.iloc[0], show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d7618",
   "metadata": {},
   "source": [
    "The explanation above can be hard to parse. The fact that the trinket is not of type `foobar` is greatly decreasing the predicted price; the fact that it is not of type `foo` is greatly increasing it. This level of granularity, including things like one-hot-encoded features, may be useful for some users - especially ML experts looking to work on the model itself. But what about other users, for example Trinket Sellers looking to use this model to help them decide on an appropriate Trinket price? Let's try some explanations presented in alternative ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8af1",
   "metadata": {},
   "source": [
    "### Interpretable feature space\n",
    "\n",
    "There are some transforms we can apply to help. Our users want to see the features that actually contribute to the model prediction, but are confused when features are presented one-hot-encoded. Let's compile a few more transformers (from the original feature space again) - including some that were also useful for getting to the model-ready feature space. We'll take a look at the interpretable feature space.\n",
    "\n",
    "We want to avoid one-hot encoded features, and present colors using English descriptions instead of HTML codes. Whether or not the explanation should include contributions from height and width separately versus the max aggregated feature is debatable - the former better matches the full information given, while the latter accurately describes how the model works. As we'll see in the next section, not all explanation types can accurately support all feature spaces, so that will factor into our choice as well.\n",
    "\n",
    "To use a transformer in the interpretable feature space, we set its `interpret` flag to `True`. We can update existing transformers' flags using the `set_flags()` method.\n",
    "\n",
    "We could make this space even more clear to human users with more descriptive feature names - but we'll add that in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf146abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpretable feature space:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   color  age    type  MAX(width,height)\n0    red   41     bar          68.784567\n1    red   71  foobar          84.261218\n2  green   90     bar          71.574072\n3   blue   32     foo          83.431874\n4  green   44  foobar          54.253466",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>color</th>\n      <th>age</th>\n      <th>type</th>\n      <th>MAX(width,height)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>red</td>\n      <td>41</td>\n      <td>bar</td>\n      <td>68.784567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>red</td>\n      <td>71</td>\n      <td>foobar</td>\n      <td>84.261218</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>green</td>\n      <td>90</td>\n      <td>bar</td>\n      <td>71.574072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>blue</td>\n      <td>32</td>\n      <td>foo</td>\n      <td>83.431874</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>green</td>\n      <td>44</td>\n      <td>foobar</td>\n      <td>54.253466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = Mappings.generate_mappings(\n",
    "    categorical_to_one_hot={\"type\": {\"type_foo\": \"foo\", \"type_bar\": \"bar\", \"type_foobar\": \"foobar\"}})\n",
    "typeDecoder = MappingsOneHotDecoder(mappings, model=False, interpret=True)\n",
    "\n",
    "colorTransformer.set_flags(interpret=True)\n",
    "maxAggregator.set_flags(interpret=True)\n",
    "interpretable_transformers = [typeDecoder, colorTransformer, maxAggregator]\n",
    "\n",
    "fit_transformers(interpretable_transformers, X_orig)\n",
    "X_interpret = run_transformers(interpretable_transformers, X_orig)\n",
    "print(\"Interpretable feature space:\")\n",
    "X_interpret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b73f8a",
   "metadata": {},
   "source": [
    "### Algorithm-ready Feature Space\n",
    "\n",
    "Many existing explanation algorithm implementations can't just take data in the interpretable form to produce an interpretable explanation - they have their own requirements for their input feature space.\n",
    "\n",
    "Pyreal handles the details of transforming both data and explanations between feature spaces, using its `Explainer` classes, which take in a `transformer` list parameter, and through the Transformer flags. Let's see how that works, and once again generate a local SHAP contribution explanation.\n",
    "\n",
    "The first thing we need to do is identify what feature space is required by the explanation type we'd like to use. We can take a look at the documentation for `ShapFeatureContribution` explainers to see that, in this case, the explanation algorithm expects data in the model-ready feature space. We can use the transformers we defined above, where those that take the data to the model-ready feature space have the flag `model=True`, and those that take the data to the interpretable feature space have the flag `interpret=True`.\n",
    "\n",
    "We do need to be a bit careful with the order here. Pyreal calls the transformers' `.transform()` methods in the order listed, backtracking as needed to undo transformations on explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f640fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.explainers import ShapFeatureContribution\n",
    "\n",
    "transformers = [maxAggregator, colorTransformer, colorEncoder, featureSelect, typeDecoder]\n",
    "\n",
    "explainer = ShapFeatureContribution(model, X_orig,\n",
    "                                    transformers=transformers,\n",
    "                                    fit_on_init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af087d60",
   "metadata": {},
   "source": [
    "We can now produce and visualize an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec460e8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MAX(width,height)'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3360\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'MAX(width,height)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13540\\2434927009.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mexplanation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_interpret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexplainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_orig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m visualize.plot_top_contributors(explanation, select_by=\"absolute\",\n\u001B[0m\u001B[0;32m      3\u001B[0m                                 values=X_interpret.iloc[0], show=True)\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\utils\\visualize.py\u001B[0m in \u001B[0;36mplot_top_contributors\u001B[1;34m(contributions, select_by, n, values, flip_colors, precision, show, filename)\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[0mfeatures\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcontributions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mvalues\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m         features = np.array([\"%s (%.*f)\" % (feature, precision, values[feature])\n\u001B[0m\u001B[0;32m     39\u001B[0m                              \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m                              \u001B[1;32melse\u001B[0m \u001B[1;34m\"%s (%s)\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\utils\\visualize.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mvalues\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m         features = np.array([\"%s (%.*f)\" % (feature, precision, values[feature])\n\u001B[1;32m---> 39\u001B[1;33m                              \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     40\u001B[0m                              \u001B[1;32melse\u001B[0m \u001B[1;34m\"%s (%s)\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m                              for feature in features])\n",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    940\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    941\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mkey_is_scalar\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 942\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    943\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    944\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_hashable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m_get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1049\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1050\u001B[0m         \u001B[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1051\u001B[1;33m         \u001B[0mloc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_values_for_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\pyreal-BgWg7FQV-py3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3361\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3362\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3363\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3364\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3365\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhasnans\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'MAX(width,height)'"
     ]
    }
   ],
   "source": [
    "explanation, X_interpret = explainer.produce(X_orig.iloc[0])\n",
    "visualize.plot_top_contributors(explanation, select_by=\"absolute\",\n",
    "                                values=X_interpret.iloc[0], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f10086",
   "metadata": {},
   "source": [
    "You may notice some warnings about missing transforms. It is not always possible to transform an explanation following a data transform - for example, in the case of MaxAggregator, we did not provide a way of distributing contribution between the features involved. Because of this, we will present our explanation using the aggregated features, to maintain explanation accuracy. We convert the data to the same interpretable state using the `i_transformers`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13948493",
   "metadata": {},
   "source": [
    "Pyreal makes it easy to switch between different explanation algorithms. We can get another feature-contribution-based explanation using the `SimpleCounterfactualContribution` explainer. This explainer requires features in a different feature space, using categorical features. To address this, we'll use the `algorithm` flag. When transformers have `algorithm=False`, the transformation will not be run until a model prediction is needed. The explanation algorithm itself will receive data transformed only using transformers with `algorithm=True`.\n",
    "\n",
    "In this case, the explanation generated has the height and width features un-aggregated, and so this is the most accurate output format. Because we decided either state could be interpretable, we will stick to the most accurate option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474530fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.explainers import SimpleCounterfactualContribution\n",
    "\n",
    "typeEncoder = OneHotEncoder(columns = [\"type\"])\n",
    "fit_transformers([typeDecoder, typeEncoder], X_orig)\n",
    "\n",
    "typeDecoder.set_flags(model=True, algorithm=True, interpret=True)\n",
    "for transformer in [typeEncoder, maxAggregator, colorTransformer, colorEncoder, featureSelect]:\n",
    "    transformer.set_flags(model=True, algorithm=False, interpret=False)\n",
    "colorTransformer.set_flags(interpret=True)\n",
    "\n",
    "explainer = SimpleCounterfactualContribution(model, X_orig,\n",
    "                                             transformers=[typeDecoder, typeEncoder, maxAggregator, colorTransformer, colorEncoder, featureSelect],\n",
    "                                             fit_on_init=True)\n",
    "\n",
    "explanation, X_interpret = explainer.produce(X_orig.iloc[0:1])\n",
    "visualize.plot_top_contributors(explanation, select_by=\"absolute\",\n",
    "                                values=X_interpret.iloc[0], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013b104",
   "metadata": {},
   "source": [
    "If we did want to get contributions of the aggregated features, we could do so without sacrificing accuracy by aggregating at the explanation level rather than the model-ready level, which is supported by this explanation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee0b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAggregator.set_flags(model=True, algorithm=True, interpret=True)\n",
    "explainer = SimpleCounterfactualContribution(model, X_orig,\n",
    "                                             transformers=[typeDecoder, maxAggregator, colorTransformer, colorEncoder, typeEncoder, featureSelect],\n",
    "                                             fit_on_init=True)\n",
    "\n",
    "explanation, X_interpret = explainer.produce(X_orig.iloc[0:1])\n",
    "visualize.plot_top_contributors(explanation, select_by=\"absolute\",\n",
    "                                values=X_interpret.iloc[0], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475cc3e",
   "metadata": {},
   "source": [
    "We can also generate global feature-based explanations using the `gfi` package - for example, the `ShapFeatureImportance` explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438a07c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyreal.explainers import ShapFeatureImportance\n",
    "\n",
    "for transformer in [colorTransformer, colorEncoder, featureSelect]:\n",
    "    transformer.set_flags(model=True, algorithm=True, interpret=False)\n",
    "typeDecoder.set_flags(model=False, algorithm=False, interpret=True)\n",
    "maxAggregator.set_flags(model=True, algorithm=True, interpret=True)\n",
    "\n",
    "explainer = ShapFeatureImportance(model, X_orig,\n",
    "                                  transformers=[maxAggregator, colorTransformer, colorEncoder, featureSelect, typeDecoder],\n",
    "                                  fit_on_init=True)\n",
    "\n",
    "explanation = explainer.produce()\n",
    "visualize.plot_top_contributors(explanation, select_by=\"absolute\", show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}