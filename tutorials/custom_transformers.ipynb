{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr9Ut95fpCN5"
   },
   "source": [
    "# Using Custom Transformers in Pyreal\n",
    "\n",
    "In this tutorial, we will be using Pyreal to investigate the California Housing Dataset.\n",
    "\n",
    "In order to generate useful explanations, we will making a few custom transformers, with functionality specific to this use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "This dataset includes 9 predictor variables, and one target variable. Each row in the dataset refers to a block of houses in California. The target variable is the median house value in this block.\n",
    "\n",
    "**Run the cell below to load in the California Housing Dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jo606ew7GUGS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-122.18</td>\n",
       "      <td>37.74</td>\n",
       "      <td>46</td>\n",
       "      <td>2103</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1339</td>\n",
       "      <td>354</td>\n",
       "      <td>2.2467</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>88900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.78</td>\n",
       "      <td>2</td>\n",
       "      <td>227</td>\n",
       "      <td>35.0</td>\n",
       "      <td>114</td>\n",
       "      <td>49</td>\n",
       "      <td>3.1591</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>-118.26</td>\n",
       "      <td>33.89</td>\n",
       "      <td>36</td>\n",
       "      <td>2230</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1395</td>\n",
       "      <td>381</td>\n",
       "      <td>2.8493</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>-118.31</td>\n",
       "      <td>33.96</td>\n",
       "      <td>46</td>\n",
       "      <td>1686</td>\n",
       "      <td>303.0</td>\n",
       "      <td>870</td>\n",
       "      <td>320</td>\n",
       "      <td>3.4643</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-122.15</td>\n",
       "      <td>37.69</td>\n",
       "      <td>36</td>\n",
       "      <td>1545</td>\n",
       "      <td>273.0</td>\n",
       "      <td>863</td>\n",
       "      <td>267</td>\n",
       "      <td>4.0109</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>192900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>-118.29</td>\n",
       "      <td>34.10</td>\n",
       "      <td>39</td>\n",
       "      <td>2196</td>\n",
       "      <td>582.0</td>\n",
       "      <td>1165</td>\n",
       "      <td>538</td>\n",
       "      <td>2.9417</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10941</th>\n",
       "      <td>-117.88</td>\n",
       "      <td>33.74</td>\n",
       "      <td>29</td>\n",
       "      <td>720</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1045</td>\n",
       "      <td>181</td>\n",
       "      <td>3.1964</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18797</th>\n",
       "      <td>-122.45</td>\n",
       "      <td>40.85</td>\n",
       "      <td>20</td>\n",
       "      <td>2701</td>\n",
       "      <td>573.0</td>\n",
       "      <td>892</td>\n",
       "      <td>358</td>\n",
       "      <td>2.7736</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16931</th>\n",
       "      <td>-122.31</td>\n",
       "      <td>37.57</td>\n",
       "      <td>42</td>\n",
       "      <td>3157</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1603</td>\n",
       "      <td>629</td>\n",
       "      <td>3.7422</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>292600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-122.27</td>\n",
       "      <td>37.90</td>\n",
       "      <td>52</td>\n",
       "      <td>2041</td>\n",
       "      <td>270.0</td>\n",
       "      <td>671</td>\n",
       "      <td>253</td>\n",
       "      <td>6.9414</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>417500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "338      -122.18     37.74                  46         2103           391.0   \n",
       "1565     -121.93     37.78                   2          227            35.0   \n",
       "7601     -118.26     33.89                  36         2230           417.0   \n",
       "5110     -118.31     33.96                  46         1686           303.0   \n",
       "678      -122.15     37.69                  36         1545           273.0   \n",
       "4226     -118.29     34.10                  39         2196           582.0   \n",
       "10941    -117.88     33.74                  29          720           174.0   \n",
       "18797    -122.45     40.85                  20         2701           573.0   \n",
       "16931    -122.31     37.57                  42         3157           676.0   \n",
       "406      -122.27     37.90                  52         2041           270.0   \n",
       "\n",
       "       population  households  median_income ocean_proximity  \\\n",
       "338          1339         354         2.2467        NEAR BAY   \n",
       "1565          114          49         3.1591       <1H OCEAN   \n",
       "7601         1395         381         2.8493       <1H OCEAN   \n",
       "5110          870         320         3.4643       <1H OCEAN   \n",
       "678           863         267         4.0109        NEAR BAY   \n",
       "4226         1165         538         2.9417       <1H OCEAN   \n",
       "10941        1045         181         3.1964       <1H OCEAN   \n",
       "18797         892         358         2.7736          INLAND   \n",
       "16931        1603         629         3.7422      NEAR OCEAN   \n",
       "406           671         253         6.9414        NEAR BAY   \n",
       "\n",
       "       median_house_value  \n",
       "338                 88900  \n",
       "1565               434700  \n",
       "7601               109600  \n",
       "5110               136300  \n",
       "678                192900  \n",
       "4226               254200  \n",
       "10941              151900  \n",
       "18797              107800  \n",
       "16931              292600  \n",
       "406                417500  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "\n",
    "AWS_BASE_URL = 'https://pyreal-data.s3.amazonaws.com/'\n",
    "data_url = urljoin(AWS_BASE_URL, \"usability_study/california.csv\")\n",
    "data = pd.read_csv(data_url)\n",
    "\n",
    "city_url = urljoin(AWS_BASE_URL, \"usability_study/cal_cities_lat_long.csv\")\n",
    "cities = pd.read_csv(city_url)\n",
    "\n",
    "data = data[data[\"median_house_value\"] < 500000]\n",
    "\n",
    "data = data.sample(5000, random_state=100)  # we will work with a truncated dataset to avoid memory crashes\n",
    "\n",
    "X = data.drop(\"median_house_value\", axis=1)\n",
    "y = data[\"median_house_value\"]\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yge_u_wO-dpB"
   },
   "source": [
    "We will be working with a pretrained model to predict the median house values for each block.\n",
    "\n",
    "**Run the code below to load in the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7FIJC51KGu53"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import requests\n",
    "\n",
    "model_url = urljoin(AWS_BASE_URL, \"usability_study/model.model\")\n",
    "r = requests.get(model_url, allow_redirects=True)\n",
    "open(urljoin('data', 'model.model'), 'wb').write(r.content)\n",
    "\n",
    "model = lightgbm.Booster(model_file=urljoin('data', 'model.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfmXzJH_HgiP"
   },
   "source": [
    "## Custom Transformers Basics\n",
    "\n",
    "Pyreal generates ML explanations using Explainer objects, which take in data Transformers through their `transformer` parameter. These Transformers take in three flags in their initialization, two of which we will use in this tutorial:\n",
    "\n",
    "- Transformers with a `model=True` flag take data from the original feature space (as we loaded in above) to the feature space used by the model.\n",
    "- Transformers with an `interpret=True` flag take data from the original feature space to a feature space more readable or interpretable by humans.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: white; border: 2px solid; padding: 10px\">\n",
    "    <b><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Note</b><br>\n",
    "    <p style=\"color: black\">\n",
    "         For information about the third transformer flag (<code>algorithm</code>), please see the <a href=\"https://github.com/sibyl-dev/pyreal/blob/dev/tutorials/advanced_explanation_generation.ipynb\">advanced explanation generation tutorial.</a>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "The Pyreal `transformer` module has some common transformers available for use, but some use-cases may require you to write your own transformer. This can be done by extending the base `Transformer` class.\n",
    "\n",
    "### Transformer Functions\n",
    "When defining a custom transformer, you will need to consider three types of functions:\n",
    "- `data_transform` (*required*): A single function that transforms the data from space A to B.\n",
    "- `inverse_transform_explanation_XXX` (*optional*): Functions that transform an explanation from space B to A. This type of function only needs to be considered if the transformer is used by the explanation algorithm and leads to the data being more obfuscated/less interpretable (ie, will have the `algorithm` flag set to True and the `interpret` flag set to False)\n",
    "- `transform_explanation_XXX` (*optional*): Functions that transform an explanation from space A to B. This type of function only needs to be considered if the transformer is used to make data and explanations more interpretable than the algorithm-ready state (ie, will have the `algorithm` flag set to False and the `interpret` flag set to True)\n",
    "\n",
    "The `transform_explantion` type functions are written per Explanation output type. For this tutorial, we will consider additive local feature contribution and additive global feature importance explanations. At the end of this tutorial, we will consider some special cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsXVvpTYaLs7"
   },
   "source": [
    "### Custom Transformer Example 1: Per-Household Averager\n",
    "\n",
    "Let's take a look at one possible custom transformer we can add, which will average the values of certain features per household. We will follow these steps to write the function:\n",
    "\n",
    "1. Define the transformer `__init__()` method, using a `super()` call for the parent `Transformer` class. The function can take optional arguments to configure the transformer. We will take in a list of columns to average.\n",
    "2. Define the `data_transform()` function, which takes an input DataFrame `x` and returns `x` after undergoing the transformation. In this case, we simply divide the selected columns by the households feature.\n",
    "3. Consider which flags we expect to be used with this transformer. In this case, our transformation will be used for the explanation algorithm, but also makes the data more interpretable, so our flags are `interpret=True` and `algorithm=True`. Therefore, we do not need to define any explanation transform functions for this use case.\n",
    "\n",
    "**Run the cell below to define the PerHouseholdAverager**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Yg9PZ5HDHD_C"
   },
   "outputs": [],
   "source": [
    "from pyreal.transformers import OneHotEncoder, MultiTypeImputer, Transformer, fit_transformers, run_transformers\n",
    "from pyreal.types.explanations.feature_based import AdditiveFeatureContributionExplanation\n",
    "\n",
    "class PerHouseholdAverager(Transformer):\n",
    "    def __init__(self, columns, **kwargs):\n",
    "        # columns: the columns to average. Must be list of strings (column names)\n",
    "        self.columns = columns\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def data_transform(self, x):\n",
    "        # Transform the data by adding a new column from total_[column] called\n",
    "        #   average_[column]. This feature represents the average value of\n",
    "        #   [column] per household.\n",
    "        for column in self.columns:\n",
    "            name = column.replace(\"total\", \"average\")\n",
    "            x[name] = x[column] / x[\"households\"]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformer Example 2: City Converter\n",
    "\n",
    "Now, let's take a look at another custom transformer, this one requiring an explanation transform. This transformer will be used to convert latitude/longitude values into city areas, based on the closest city to the given coordinates.\n",
    "\n",
    "Again, we will follow the following steps:\n",
    "\n",
    "1. Define the transformer `__init__()` method, using a `super()` call for the parent `Transformer` class. The function can take optional arguments to configure the transformer. In this case, we will not take in any parameters.\n",
    "2. Define the `data_transform()` function, which takes an input DataFrame `x` and returns `x` after undergoing the transformation. In this case, we convert long/lat values to nearby cities.\n",
    "3. Consider which flags we expect to be used with this transformer. In this case, our transformation will be used to make the data more interpretable, but will not be fed into the model, so our flags are `interpret=True` and `algorithm=model=False`. Therefore, the `transform_explanation_XXX` functions will be called, but not the `inverse_transform_explanation` functions.\n",
    "4. Consider the explanation output types you are interested in. For now, let's consider additive local feature contribution and additive global feature importance explanations. These are explanations that provide an importance weighting to each feature, and where these importances can be meaningfully added together to represent the importance of multiple features. We will need to define `transform_explanation_additive_feature_contribution` and `transform_explanation_additive_feature_importance` functions.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: white; border: 2px solid; padding: 10px\">\n",
    "    <b><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Note</b><br>\n",
    "    <p style=\"color: black\">\n",
    "         Note that explanation output types are heirarchial, and Pyreal will use the explanation transforms of higher-level types when the lower-level types are not available. For example, if <code>transform_explanation_additive_feature_contribution</code> is not defined, Pyreal will attempt to use <code>transform_explanation_feature_contribution</code>.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityConverter(Transformer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.cities = cities\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def data_transform(self, x):\n",
    "        # Converts latitude/longitude coordinates to closest city name. Note that\n",
    "        #    we are using a very rough estimate here, assuming constant size.\n",
    "        flag = False\n",
    "        if isinstance(x, pd.Series):\n",
    "            x = x.to_frame().T\n",
    "            flag = True\n",
    "        for index, row in self.cities.iterrows():\n",
    "            lat = row[\"Latitude\"]\n",
    "            lon = row[\"Longitude\"]\n",
    "            x.loc[(x[\"latitude\"] > lat-0.1) & (x[\"latitude\"] < lat+0.1) & (x[\"longitude\"] > lon-0.1) & (x[\"longitude\"] < lon+0.1), \"city\"] = row[\"Name\"]\n",
    "        x = x.drop(\"latitude\", axis=1)\n",
    "        x = x.drop(\"longitude\", axis=1)\n",
    "        if flag:\n",
    "            x = x.squeeze(axis=0)\n",
    "        return x\n",
    "\n",
    "    def transform_explanation_additive_feature_contribution(self, explanation):\n",
    "        df = explanation.get()  # A DataFrame with one row per instance and one column per feature\n",
    "        return AdditiveFeatureContributionExplanation(helper_sum_lat_long_columns(df))\n",
    "\n",
    "    def transform_explanation_additive_feature_importance(self, explanation):\n",
    "        df = explanation.get()  # A DataFrame with one row and one column per feature\n",
    "        return AdditiveFeatureImportanceExplanation(helper_sum_lat_long_columns(df))\n",
    "\n",
    "    def helper_sum_lat_long_columns(explanation):\n",
    "        # In the case of additive contributions or importances, we can combine the latitude and\n",
    "        #    longitude explanation contributions by summing to get the city contribution. In this\n",
    "        #    case, our implementation is almost identical for both types of explanations\n",
    "        explanation[\"city\"] = explanation[\"longitude\"] + explanation[\"latitude\"]\n",
    "        explanation = explanation.drop(\"longitude\", axis=1)\n",
    "        explanation = explanation.drop(\"latitude\", axis=1)\n",
    "        return explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPtavPkfKf91"
   },
   "source": [
    "## Using Transformers\n",
    "\n",
    "In the next code cell, we will using our custom defined transformers, as well as some predefined Pyreal transformers, to generate local and global explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: training_size not provided. Defaulting to train with full dataset, running time might be slow.\n",
      "Warning: training_size not provided. Defaulting to train with full dataset, running time might be slow.\n",
      "Warning: training_size not provided. Defaulting to train with full dataset, running time might be slow.\n",
      "Warning: training_size not provided. Defaulting to train with full dataset, running time might be slow.\n"
     ]
    }
   ],
   "source": [
    "from pyreal.explainers import LocalFeatureContribution, GlobalFeatureImportance\n",
    "from pyreal.transformers import OneHotEncoder, MultiTypeImputer, fit_transformers\n",
    "\n",
    "# Initialize and fit transformers using fit_transformers\n",
    "transformers = [MultiTypeImputer(model=True),\n",
    "                OneHotEncoder(columns=\"ocean_proximity\", model=True),\n",
    "                PerHouseholdAverager(columns=[\"total_bedrooms\", \"total_rooms\"], model=True, interpret=True),\n",
    "                CityConverter(model=False, interpret=True)]\n",
    "fit_transformers(transformers, X)\n",
    "\n",
    "# Initialize and fit the explainers\n",
    "local_explainer = LocalFeatureContribution(model=model, x_train_orig=X, transformers=transformers, fit_on_init=True)\n",
    "global_explainer = GlobalFeatureImportance(model=model, x_train_orig=X, transformers=transformers, fit_on_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L5N5xe0dIuTt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyreal.types.explanations.feature_based.AdditiveFeatureContributionExplanation object at 0x0000022CCD6EBDF0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'helper_sum_lat_long_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16836\\2349173517.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Generate and visualize the explanation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mlocal_explanation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_interpret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlocal_explainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;31m#global_explanation = global_explainer.produce()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\explainers\\lfc\\base.py\u001B[0m in \u001B[0;36mproduce\u001B[1;34m(self, x_orig)\u001B[0m\n\u001B[0;32m     57\u001B[0m             \u001B[0mx_orig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx_orig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[0mcontributions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_contributions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_orig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m         \u001B[0mcontributions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_interpret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_explanation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontributions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_orig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mseries\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mx_interpret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx_interpret\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\explainers\\base.py\u001B[0m in \u001B[0;36mtransform_explanation\u001B[1;34m(self, explanation, x_orig)\u001B[0m\n\u001B[0;32m    308\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0malgorithm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 310\u001B[1;33m                     \u001B[0mexplanation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_explanation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    311\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mBreakingTransformError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m                     log.warning(\"Transformer class %s does not have the required explanation \"\n",
      "\u001B[1;32m~\\Documents\\github\\pyreal\\pyreal\\transformers\\base.py\u001B[0m in \u001B[0;36mtransform_explanation\u001B[1;34m(self, explanation)\u001B[0m\n\u001B[0;32m    246\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAdditiveFeatureContributionExplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 248\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_explanation_additive_feature_contribution\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    249\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mAdditiveFeatureImportanceExplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform_explanation_additive_feature_importance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16836\\2828387693.py\u001B[0m in \u001B[0;36mtransform_explanation_additive_feature_contribution\u001B[1;34m(self, explanation)\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtransform_explanation_additive_feature_contribution\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexplanation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# A DataFrame with one row per instance and one column per feature\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mAdditiveFeatureContributionExplanation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhelper_sum_lat_long_columns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtransform_explanation_additive_feature_importance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexplanation\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'helper_sum_lat_long_columns' is not defined"
     ]
    }
   ],
   "source": [
    "from pyreal.utils import visualize\n",
    "\n",
    "# Generate and visualize the explanation\n",
    "local_explanation, x_interpret = local_explainer.produce(X.iloc[0])\n",
    "#global_explanation = global_explainer.produce()\n",
    "\n",
    "print(local_explanation, x_interpret)\n",
    "\n",
    "visualize.plot_top_contributors(local_explanation, values=x_interpret, select_by=\"absolute\", show=True)\n",
    "visualize.plot_top_contributors(global_explanation, select_by=\"absolute\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSth0yZ1A2vW"
   },
   "source": [
    "# Generating Global Explanations\n",
    "\n",
    "You can now start using Pyreal Explainers to investigate the model. Remember to take a look at the links at the top of this page as needed.\n",
    "\n",
    "We will begin by generating a *global* explanation, or an explanation of how the model makes predictions in general.\n",
    "\n",
    "⭐**In the next cell, initialize, fit, and call the produce function on a `GlobalFeatureImportance` Explainer.**\n",
    "\n",
    "⭐**Remember, you will need to begin by initalizing and fitting the required transformers. Revisit the cells above for details on the transformers you will need and their flags. You can use the `fit_transformers` function to quickly fit them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBwHIp18D50V"
   },
   "outputs": [],
   "source": [
    "from pyreal.explainers import GlobalFeatureImportance\n",
    "from pyreal.transformers import fit_transformers\n",
    "from pyreal.utils import visualize\n",
    "\n",
    "# Step one: Initialize and fit transformers using fit_transformers\n",
    "# ---- Your code here ----\n",
    "\n",
    "# Step two: Initialize and fit the explainer\n",
    "# ---- Your code here ----\n",
    "\n",
    "# Step three: Generate and visualize the explanation\n",
    "# ---- Your code here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8gOOucyKt5A"
   },
   "source": [
    "⭐**Now, please press the \"next\" button on the Qualtrics survey tab and answer the next set of questions, referencing this tab as needed.** ⭐\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuMCOFODGoUa"
   },
   "source": [
    "# Generating Local Explanations\n",
    "\n",
    "⭐ **Now, please consider the `sample_block` listed below, which refers to a hypothetical block of houses that might exist in California. Run the code block.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bultpbt_Ktq_"
   },
   "outputs": [],
   "source": [
    "sample_block = pd.Series({\n",
    "  \"longitude\": -122.23,\n",
    "  \"latitude\": 37.88,\n",
    "  \"housing_median_age\": 16,\n",
    "  \"total_rooms\": 672,\n",
    "  \"total_bedrooms\": 230,\n",
    "  \"population\": 220,\n",
    "  \"households\": 52,\n",
    "  \"median_income\":  5.3252,\n",
    "  \"ocean_proximity\": \"NEAR BAY\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB0VFOR7K63p"
   },
   "source": [
    "We will now generate a *local* explanation, or an explanation of why the model makes the prediction it does for the specific `sample_block` above.\n",
    "\n",
    "⭐**In the next cell, initialize, fit, and call the produce function on a `LocalFeatureContribution` Explainer. Generate an explanation for the prediction of the `sample_block` above.**\n",
    "\n",
    "⭐**You can likely reuse the already-fit transformers from the previous section. If you would like to use any more, remember to fit them before using.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qyjModSK6UQ"
   },
   "outputs": [],
   "source": [
    "from pyreal.explainers import LocalFeatureContribution\n",
    "from pyreal.transformers import fit_transformers\n",
    "from pyreal.utils import visualize\n",
    "\n",
    "# Step one: Initialize and fit the explainer\n",
    "# ---- Your code here ----\n",
    "\n",
    "# Step two: Generate and visualize the explanation\n",
    "# ---- Your code here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ55r__NS8kQ"
   },
   "source": [
    "⭐**Now, please press the \"next\" button on the Qualtrics survey tab and answer the next set of questions, referencing this tab as needed.** ⭐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbdTemKIf6lp"
   },
   "source": [
    "# Downloading This Notebook\n",
    "\n",
    "⭐**Once you have finished answering all questions, save and download this notebook to a location of your choosing using `File` &#8594; `Download` &#8594; `Download .ipynb`, in the upper left toolbar of this page. You will need to upload it shortly to the Qualtrics survey.**\n",
    "\n",
    "⭐**Please return to the Qualtrics survey now and press next, then follow instructions to upload this notebook, and then answer final reflection questions.**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pyreal Usability Study",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}