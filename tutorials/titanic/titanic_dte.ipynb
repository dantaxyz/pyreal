{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source:\n",
    "Kaggle. (2012). Titanic: Machine Learning from Disaster. Retrieved from https://www.kaggle.com/c/titanic/data.\n",
    "\n",
    "In this tutorial, we will walk through the process of getting a decision tree-based explanation for model predictions on the Titanic dataset. We will see which features contribute most to survival predictions for passengers who were on board the Titanic. The data loading and pre-processing steps are identical to tutorials of the global and local feature contributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by loading the data, and writing out human-readable descriptions of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pyreal.applications import titanic\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "x_orig, y = titanic.load_titanic_data()\n",
    "\n",
    "x_train_orig, x_test_orig, y_train, y_test = train_test_split(x_orig, y, test_size=.20)\n",
    "\n",
    "print(\"Features:\", x_orig.columns.values)\n",
    "\n",
    "feature_descriptions = {\n",
    "    \"PassengerId\": \"Passenger ID\",\n",
    "    \"Pclass\": \"Ticket Class\",\n",
    "    \"SibSp\": \"Number of siblings/spouses aboard\",\n",
    "    \"Parch\": \"Number of parents/children aboard\",\n",
    "    \"Ticket\": \"Ticket Number\",\n",
    "    \"Fare\": \"Passenger Fare\",\n",
    "    \"Cabin\": \"Cabin Number\",\n",
    "    \"Embarked\": \"Port of Embarkment\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.transformers import OneHotEncoder, ColumnDropTransformer, MultiTypeImputer\n",
    "from pyreal.transformers import fit_transformers, run_transformers\n",
    "\n",
    "column_drop = ColumnDropTransformer([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "imputer = MultiTypeImputer()\n",
    "one_hot_encoder = OneHotEncoder([\"Sex\", \"Embarked\"])\n",
    "\n",
    "transformers = [column_drop, imputer, one_hot_encoder]\n",
    "fit_transformers(transformers, x_train_orig)\n",
    "x_transform_train = run_transformers(transformers, x_train_orig)\n",
    "x_transform_test = run_transformers(transformers, x_test_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will make the transformers. `Pyreal`'s built-in transformers all have explanation transforms, which bring explanations from the model form to the interpretable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(x_transform_train, y_train)\n",
    "\n",
    "preds = model.predict(x_transform_test)\n",
    "print(\"Test accuracy: %.2f\" % (np.mean(preds==y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make the decision tree explainer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.explainers import DecisionTreeExplainer\n",
    "\n",
    "dte = DecisionTreeExplainer(model=model, x_train_orig=x_train_orig, is_classifier=True, max_depth=5,\n",
    "                            m_transformers=transformers, e_transformers=transformers,\n",
    "                            feature_descriptions=feature_descriptions, fit_on_init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `produce()` function of a `DecisionTreeExplainer` class returns a `sklearn.tree.DecisionTreeClassifier` or `DecisionTreeRegressor` object. We can also visualize the explanation by plotting the explanation tree.\n",
    "\n",
    "To better make sense of the tree diagram, we can call `dte.return_features()` to help the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decision_tree = dte.produce()\n",
    "\n",
    "feature_names = dte.return_features()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "\n",
    "plot_tree(decision_tree, feature_names=feature_names, class_names=[\"died\", \"survived\"],\n",
    "              impurity=False, fontsize=10, ax=ax, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree can also tell us how each feature contributes to the prediction of the survival of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyreal.utils import visualize\n",
    "\n",
    "importances = dte.produce_importances()\n",
    "\n",
    "visualize.plot_top_contributors(importances, select_by=\"absolute\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}